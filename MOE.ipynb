{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sparse Mixture of Experts ---> Model 1"
      ],
      "metadata": {
        "id": "WOjaSHqivkq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyreadstat torch torchvision torchaudio scikit-learn --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wr8JlTVvrqd",
        "outputId": "dd8d4125-a4cb-4f67-d2f2-7b0cb02fb4d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/666.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m501.8/666.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.4/666.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3oCT-mwRQk",
        "outputId": "6abff8d6-8283-4606-bbfe-605caf91529d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyreadstat\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/LLCP2020.XPT\"  # change path if needed\n",
        "\n",
        "print(\"⏳ Loading XPT file...\")\n",
        "df, meta = pyreadstat.read_xport(file_path)\n",
        "\n",
        "print(\"✅ Raw dataframe shape:\", df.shape)\n",
        "print(\"📋 First 50 columns:\", df.columns[:50].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njjht5rhzJZw",
        "outputId": "f2c7ff11-97ee-4700-b66e-a05008c10cb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Loading XPT file...\n",
            "✅ Raw dataframe shape: (401958, 279)\n",
            "📋 First 50 columns: ['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'SEQNO', '_PSU', 'CTELENM1', 'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHONE', 'LADULT1', 'COLGSEX', 'NUMADULT', 'LANDSEX', 'NUMMEN', 'NUMWOMEN', 'RESPSLCT', 'SAFETIME', 'CTELNUM1', 'CELLFON5', 'CADULT1', 'CELLSEX', 'PVTRESD3', 'CCLGHOUS', 'CSTATE1', 'LANDLINE', 'HHADULT', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'EXERANY2', 'SLEPTIM1', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_cols = [\n",
        "    \"AGEG5YR\",\"SEXVAR\",\"BMI5\",\"SMOKE100\",\"SMOKDAY2\",\"STOPSMK2\",\"ALCDAY5\",\"AVEDRNK2\",\"DRNK3GE5\",\"DIABETE4\",\n",
        "    \"TOLDHI2\",\"CVDCRHD4\",\"CVDSTRK3\",\"CHCCOPD1\",\"HAVARTH3\",\"CHCKIDNY\",\"ADDEPEV3\",\"MENTHLTH\",\"PHYSHLTH\",\"HLTHPLN1\",\n",
        "    \"PERSDOC2\",\"MEDCOST\",\"CHECKUP1\",\"EXERANY2\",\"SLEPTIM1\",\"FLUSHOT7\",\"PNEUVAC4\",\"HIVTST7\",\"GENHLTH\",\"POORHLTH\",\n",
        "    \"QLACTLM2\",\"USEEQUIP\",\"DEAF\",\"BLIND\",\"DECIDE\",\"DIFFWALK\",\"DIFFDRES\",\"DIFFALON\",\"EMPLOY1\",\"EDUCA\",\n",
        "    \"INCOME2\",\"MARITAL\",\"RENTHOM1\",\"VETERAN3\",\"CHILDREN\",\"HCVU651\"\n",
        "]\n",
        "\n",
        "target_col = \"CVDINFR4\"  # heart attack label\n",
        "\n",
        "# check which columns exist\n",
        "missing = [c for c in selected_cols+[target_col] if c not in df.columns]\n",
        "print(\"Missing columns:\", missing)\n",
        "\n",
        "# keep only if available\n",
        "df = df[[c for c in selected_cols if c in df.columns] + [target_col]].copy()\n",
        "df = df.rename(columns={target_col: \"HeartAttack\"})\n",
        "\n",
        "print(\"✅ Subset shape:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58N1B7xCzwF0",
        "outputId": "377f95c6-9fe1-4471-eb8b-bc53fadb430e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing columns: ['AGEG5YR', 'BMI5', 'AVEDRNK2', 'TOLDHI2', 'CHCCOPD1', 'HAVARTH3', 'CHCKIDNY', 'QLACTLM2', 'USEEQUIP', 'HCVU651']\n",
            "✅ Subset shape: (401958, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Replace BRFSS missing codes with NaN\n",
        "df = df.replace({7: np.nan, 9: np.nan, 77: np.nan, 99: np.nan, 997: np.nan, 999: np.nan})\n",
        "\n",
        "# Drop rows with NaN\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Split features and target\n",
        "X_df = df.drop(columns=['HeartAttack']).astype(np.float32)\n",
        "y = df['HeartAttack'].astype(int).to_numpy()\n",
        "\n",
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_df)\n",
        "\n",
        "print(\"✅ Final X shape:\", X.shape)\n",
        "print(\"📊 Target distribution:\", np.bincount(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYGYjf_IzxsI",
        "outputId": "440a266b-1fc0-4d0b-a190-2284cc13d958"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final X shape: (5082, 36)\n",
            "📊 Target distribution: [   0  293 4789]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BRFSS coding: 1 = Yes, 2 = No\n",
        "# We remap to 1 = HeartAttack, 0 = No HeartAttack\n",
        "y = np.where(y == 1, 1, 0)\n",
        "\n",
        "print(\"✅ Fixed target distribution:\", np.bincount(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_X9l5lK0Yxt",
        "outputId": "09b95748-7b70-4613-f709-40a4632b8cb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed target distribution: [4789  293]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import balanced_accuracy_score, recall_score, roc_auc_score, roc_curve\n",
        "\n",
        "def youdens_j_threshold(y_true, y_prob):\n",
        "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
        "    j = tpr - fpr\n",
        "    return thr[np.argmax(j)]\n",
        "\n",
        "def fit_evaluate(model, X, y, n_splits=5, random_state=42):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    bal_accs, macro_recalls, recall1s, aucs, thrs = [], [], [], [], []\n",
        "    for tr, te in skf.split(X, y):\n",
        "        Xtr, Xte = X[tr], X[te]\n",
        "        ytr, yte = y[tr], y[te]\n",
        "        model.fit(Xtr, ytr)\n",
        "        p = model.predict_proba(Xte)[:,1]\n",
        "        thr = youdens_j_threshold(yte, p)\n",
        "        thrs.append(thr)\n",
        "        yhat = (p >= thr).astype(int)\n",
        "        bal_accs.append(balanced_accuracy_score(yte, yhat))\n",
        "        macro_recalls.append(recall_score(yte, yhat, average=\"macro\", zero_division=0))\n",
        "        recall1s.append(recall_score(yte, yhat, pos_label=1))\n",
        "        aucs.append(roc_auc_score(yte, p))\n",
        "    return {\n",
        "        \"Balanced Accuracy\": np.mean(bal_accs),\n",
        "        \"Macro Recall\": np.mean(macro_recalls),\n",
        "        \"Recall Class 1\": np.mean(recall1s),\n",
        "        \"AUC\": np.mean(aucs),\n",
        "        \"Youden Threshold\": np.mean(thrs)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "NQUiv_O_z_N2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class MoEClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim, n_experts=4, hidden=64, lr=1e-3, epochs=8, batch_size=4096, l2=1e-5, device=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.n_experts = n_experts\n",
        "        self.hidden = hidden\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.l2 = l2\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, self.hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden, self.n_experts)\n",
        "        )\n",
        "        self.experts = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(self.input_dim, self.hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.hidden, self.hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(self.hidden, 1)\n",
        "            ) for _ in range(self.n_experts)\n",
        "        ])\n",
        "        self.crit = nn.BCEWithLogitsLoss()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.gate.to(self.device)\n",
        "        self.experts.to(self.device)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        Xt = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        yt = torch.tensor(y.reshape(-1,1), dtype=torch.float32).to(self.device)\n",
        "        params = list(self.gate.parameters()) + list(self.experts.parameters())\n",
        "        opt = optim.Adam(params, lr=self.lr, weight_decay=self.l2)\n",
        "\n",
        "        n = Xt.shape[0]\n",
        "        idx = torch.arange(n, device=self.device)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            perm = idx[torch.randperm(n)]\n",
        "            for i in range(0, n, self.batch_size):\n",
        "                batch = perm[i:i+self.batch_size]\n",
        "                xb = Xt[batch]; yb = yt[batch]\n",
        "                opt.zero_grad()\n",
        "                g_logits = self.gate(xb)\n",
        "                g_prob = torch.softmax(g_logits, dim=1)\n",
        "                exp_logits = torch.cat([e(xb) for e in self.experts], dim=1)\n",
        "                mix_logits = (g_prob * exp_logits).sum(dim=1, keepdim=True)\n",
        "                loss = self.crit(mix_logits, yb)\n",
        "                loss.backward(); opt.step()\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        Xt = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            g_prob = torch.softmax(self.gate(Xt), dim=1)\n",
        "            exp_logits = torch.cat([e(Xt) for e in self.experts], dim=1)\n",
        "            mix_logits = (g_prob * exp_logits).sum(dim=1, keepdim=True)\n",
        "            p1 = self.sigmoid(mix_logits).cpu().numpy().ravel()\n",
        "        return np.vstack([1-p1, p1]).T\n"
      ],
      "metadata": {
        "id": "Xyo5C1AI0EfC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "moe = MoEClassifier(input_dim=X.shape[1], n_experts=4, hidden=64, lr=1e-3, epochs=8, batch_size=4096)\n",
        "results = fit_evaluate(moe, X, y)\n",
        "\n",
        "print(\"📊 Mixture-of-Experts Results:\")\n",
        "for k,v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcHOAvqz0H9b",
        "outputId": "881bd7a6-9842-435f-c4aa-78ede04b39b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "📊 Mixture-of-Experts Results:\n",
            "Balanced Accuracy: 0.6704\n",
            "Macro Recall: 0.6704\n",
            "Recall Class 1: 0.6512\n",
            "AUC: 0.6981\n",
            "Youden Threshold: 0.1973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression (baseline)\n",
        "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", solver=\"lbfgs\")\n",
        "\n",
        "results_lr = fit_evaluate(log_reg, X, y)\n",
        "\n",
        "print(\"📊 Logistic Regression Results:\")\n",
        "for k,v in results_lr.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zedq2251e_2",
        "outputId": "3629c366-b511-461f-b2c5-316cd667468e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Logistic Regression Results:\n",
            "Balanced Accuracy: 0.7703\n",
            "Macro Recall: 0.7703\n",
            "Recall Class 1: 0.7304\n",
            "AUC: 0.8244\n",
            "Youden Threshold: 0.4627\n"
          ]
        }
      ]
    }
  ]
}